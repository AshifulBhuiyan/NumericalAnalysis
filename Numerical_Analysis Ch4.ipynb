{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiation and Integration\n",
    "Composite Simpsons Rule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f(x):\n",
    "    return np.sqrt(1-(x)**2) #semicircle\n",
    "\n",
    "def g(x):\n",
    "    return (x**4*(1-x)**4/(1+x**2))\n",
    "\n",
    "#composite simpsons rule\n",
    "def CSR(f, a, b, N):\n",
    "    h = (b-a)/N\n",
    "    XI0 = f(a) + f(b)\n",
    "    XI1 = 0\n",
    "    XI2 = 0\n",
    "    for i in range(N-1):\n",
    "        X = a+i*h\n",
    "        if i%2 == 0:\n",
    "            XI2 = XI2 +f(X)\n",
    "        else:\n",
    "            XI1 = XI1 + f(X)\n",
    "    XI = h*(XI0 + 2 * XI2 + 4 * XI1)/3\n",
    "    return XI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1405233503531225"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*CSR(f, -1,1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSR(g, 0,1, 5000)+np.pi==22/7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying my best with Numerical Differentiation:\n",
    "$$\n",
    "f'(x_0) = \\lim_{h \\rightarrow 0} \\frac{f(x_0 +h) - f(x_0)}{h}\n",
    "$$\n",
    "\n",
    "To approximate $f'(x_0)$ , suppose first that $x_0 \\in (a,b),$ where $ f \\in C^2 \\left[ a,b \\right] $ and that $x_1 = x_0 +h$ for some $h \\neq 0$ that is sufficiently small to ensure that $x_1 \\in \\left[ a,b \\right]$.\n",
    "\n",
    "We can construct the first Lagrange Polynomial $P_{0,1}(x)$ for $f$ determined by $x_0$ and $x_1$ with the error term:\n",
    "\n",
    "$$\n",
    "f(x) = P_{0,1}(x) + \\frac{(x-x_0)(x-x_1)}{2!}f''(\\xi (x)) \\\\\n",
    "= \\frac{f(x_0)(x-x_0-h)}{-h} + \\frac{f(x_0+h)(x-x_0)}{h} + \\frac{(x-x_0)(x-x_1)}{2!}f''(\\xi (x))\n",
    "$$\n",
    "Differentiate:\n",
    "\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{f(x_0 +h)-f(x_0)}{h} + D_x \\left[ \\frac{f(x_0+h)(x-x_0)}{h} + \\frac{(x-x_0)(x-x_1)}{2!}f''(\\xi (x)) \\right]\n",
    "$$\n",
    "\n",
    "Ignoring the error terms:\n",
    "\n",
    "$$\n",
    "f'(x) \\approx \\frac{f(x_0 +h)-f(x_0)}{h}\n",
    "$$\n",
    "\n",
    "Little info on $D_x f''(\\xi (x))$, so truncation error can't be estimated. But when $x = x_0$ , $D_x f''(\\xi (x))=0$, so we get a simple formula:\n",
    "\n",
    "$$\n",
    "f'(x_0) = \\frac{f(x_0 +h)-f(x_0)}{h} - \\frac{h}{2} f''(\\xi)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error bound: $M|h|/2$, where $M$ is a bound on $|f''(X)|$ for $x \\in [x_0, x_0+h]$\n",
    "- **Forward-difference** if $h>0$ \n",
    "- **Backward-difference** if $h<0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.log(x)\n",
    "def fwdDiff(f, x0, h):\n",
    "    return (f(x0+h) - f(x0))/h\n",
    "\n",
    "def backDiff(f,x0, h):\n",
    "    return (-f(x0-h) + f(x0))/h\n",
    "\n",
    "def threePtMidPt(f,x0,h):\n",
    "    return (fwdDiff(f,x0,h)+backDiff(f,x0,h))/2\n",
    "\n",
    "def threePtEndPt(f,x0,h):\n",
    "    return (-3*f(x0) +4*f(x0+h) - f(x0+2*h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.555544265793817, 0.5555612712535352)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threePtEndPt(f, 1.8, 0.01), threePtMidPt(f, 1.8, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Pt Mid and End Point Formula:\n",
    "def f(x):\n",
    "    return np.log(x)\n",
    "\n",
    "def fivePtMidPt(f, x0, h):\n",
    "    return (f(x0-2*h)-8*f(x0-h) +8*f(x0+h) - f(x0+2*h))/(12*h)\n",
    "\n",
    "def fivePtEndPt(f, x0, h):\n",
    "    return (-25*f(x0)+48*f(x0+h) -36*f(x0+2*h) +16* f(x0+3*h)- 3*f(x0+4*h))/(12*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5555555531293407, 0.5555555551321312, 0.5540180375615322)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fivePtEndPt(f, 1.8, 0.01), fivePtMidPt(f, 1.8, 0.01), fwdDiff(f, 1.8, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd derivative Midpt formula\n",
    "def secondDerivativeMidPt(f, x0, h):\n",
    "    return (f(x0-h) -2* f(x0)+f(x0+h))/h**2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Richardson's Extrapolation\n",
    "- high-accuracy results while using low-order formulas\n",
    "- extrapolation applied whenever it is known that an approximation technique has an error term with a predictable form\n",
    "    - suppose we have formula $N_1(h)$ that approximates an unknown constant $M$ and that the truncation error involved with the approx has form:\n",
    "\n",
    "$$\n",
    "M-N_1(h) = K_1h+K_2 h^2 + \\dots + K_nh^n\n",
    "$$\n",
    "for some collection of (unknown) constants $K_n$\n",
    "\n",
    "The truncation error is $O(h)$ so unless there was alarge variation in magnitude among the constants $K_n$ , we have:\n",
    "\n",
    "$$\n",
    "M-N_1(0.1) \\approx 0.1K_1,  \\quad \\text{i.e} \\quad M-N_1(h) \\approx hK_1\n",
    "$$\n",
    "\n",
    "To see how to generate extrapolation formulas, consider $O(h)$ for approximating $M$:\n",
    "\n",
    "$$\n",
    "M=N_1(h) + K_1h+K_2 h^2 + \\dots + K_nh^n \\quad (4.10)\n",
    "$$\n",
    "\n",
    "If we replace parameter $h$ by half its value: We get a second $O(h)$ approximation formula:\n",
    "\n",
    "$$\n",
    "M = N_1\\left(\\frac{h}{2}\\right)+ K_1\\left(\\frac{h}{2}\\right)+K_2 \\left(\\frac{h^2}{4}\\right) + \\dots + K_n\\left(\\frac{h^n}{2^n}\\right) \\quad (4.11)\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting eq 4.10 from twice Eq 4.11 eliminates the term involving $K_1$ and gives:\n",
    "$$\n",
    "2(4.11) - (4.10) = \\\\\n",
    "2M - M= M=N_1(\\frac{h}{2})  + \\dots + K_n\\left(\\frac{h^n}{(2^{n-1})}-h^n\\right)\n",
    "$$\n",
    "Define \n",
    "\n",
    "$$\n",
    "N_2(h) = N_1 \\left(\\frac{h}{2}\\right) + \\left[ N_1\\left( \\frac{h}{2} - N_1(h)\\right) \\right]\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "M = N_2(h) - \\frac{K_2}{2}h^2 - \\dots - \\frac{nK_n}{2^{n-1}} h^n\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numerical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
